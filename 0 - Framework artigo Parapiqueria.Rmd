---
title: "Framework_Artigo Parapiqueria"
author:
  name: Gabriel Santos
output: 
  html_document:
    self_contained: true
    cache: false
    df_print: paged
    theme: paper
    code_folding: show
    toc: true
    toc_float:
      collapsed: true
    number_sections: false
params:
  update_dat: !r paste(format(Sys.time(), '%Y-%m-%d (%H:%M:%S)'))
  orig_dat: 05/08/2024
editor_options:
  markdown:
    wrap: 72
---

**Created in**: `r params$orig_dat`

**Updated in:** `r params$update_dat`

<!-- Setup -->

```{css, echo=FALSE}
.scroll {
  max-height: 500px;
  overflow-y: auto;
  background-color: inherit;
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, digits=3) 
options(knitr.table.format = "html")

```

<!-- Start here -->

```{r eval=FALSE, include=FALSE}
rm(list=ls());gc()
```

# README

<!--#  Reorganizar essa ordem e atualizar os novos tópicos adicionados: elasticidade e LTRE-->

1.  Creates an accessory function to automatize the implementation of the Quadratic Programming inverse method (QP therefore)

2.  Estimate survival, stasis and growth using the `QPmat`from `popbio` package

    1.  Step 1. Define the rules/constraints that must be given to the QP - Quadratic programming

        -   $C$, $b$ , non-zeros
        -   Automatise this process with a dedicated ancillary function `WoodPar`

3.  Reach a best method to estimate recruitment, as it cannot be directly estimated with QP

4.  Apply QP and retrieve MPMs

5.  Complement MPMs with recruitment

6.  Calculate lambda and plot results

7.  Population viability

    7.1. Simulations with reducing vital rates'

# 1. Packages and SessionInfo

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(popbio)
library(ggplot2)
library(tidyverse)
library(openxlsx)
library(ggrepel)
library(ggridges)
library(broom)

set.seed(1)
sessionInfo()

```

An ancillary function to optimise statistical report

```{r, label="statrep function"}
statrep <- function(data, group_vars, value_var = "value", round = NULL) {
  data_summary <- data %>%
    group_by(across(all_of(group_vars))) %>%
    summarise(
      Mean = mean(.data[[value_var]], na.rm = TRUE),
      SD = sd(.data[[value_var]], na.rm = TRUE),
      N = n(),
      SE = SD / sqrt(N),
      CI = 1.96 * SE,
      lower95 = quantile(.data[[value_var]], 0.025, na.rm = TRUE),
      higher95 = quantile(.data[[value_var]], 0.975, na.rm = TRUE),
      .groups = "drop"
    )
    # Define if values should be rounded
  if (is.null(round)) {
    round_val <- 3
  } else if (identical(round, FALSE)) {
    return(data_summary)  # Não arredonda, retorna direto
  } else {
    round_val <- round
  }
  
  # if round is informed, round it accordingly
  data_summary %>%
    mutate(across(where(is.numeric), ~round(.x, round_val)))
}

```

# 2. Data Loading and standardization

```{r}
Mar22<-read.xlsx("Data/Dados parapiqueria - Completo - Consolidado 10Jun2025.xlsx",sheet="Março2022")
Abr22<-read.xlsx("Data/Dados parapiqueria - Completo - Consolidado 10Jun2025.xlsx",sheet="Abril2022")
Mai22<-read.xlsx("Data/Dados parapiqueria - Completo - Consolidado 10Jun2025.xlsx",sheet="Maio2022")

### 2023
Mar23<-read.xlsx("Data/Dados parapiqueria - Completo - Consolidado 10Jun2025.xlsx",sheet="Março2023")
Abr23<-read.xlsx("Data/Dados parapiqueria - Completo - Consolidado 10Jun2025.xlsx",sheet="Abril2023")
Mai23<-read.xlsx("Data/Dados parapiqueria - Completo - Consolidado 10Jun2025.xlsx",sheet="Maio2023")

### 2024
Mar24<-read.xlsx("Data/Dados parapiqueria - Completo - Consolidado 10Jun2025.xlsx",sheet="Março2024")
Abr24<-read.xlsx("Data/Dados parapiqueria - Completo - Consolidado 10Jun2025.xlsx",sheet="Abril2024")
Mai24<-read.xlsx("Data/Dados parapiqueria - Completo - Consolidado 10Jun2025.xlsx",sheet="Maio2024")

### 2025
Mar25<-read.xlsx("Data/Dados parapiqueria - Completo - Consolidado 10Jun2025.xlsx",sheet="Março2025")
Abr25<-read.xlsx("Data/Dados parapiqueria - Completo - Consolidado 10Jun2025.xlsx",sheet="Abril2025")
Mai25<-read.xlsx("Data/Dados parapiqueria - Completo - Consolidado 10Jun2025.xlsx",sheet="Maio2025")

```

## 2.1. Prepare final datasets: Merging censuses & summarise

-   Step 1: Merge monthly censuses Merge census across the years

    Censuses are performed every March, April and May and need to merged to produce a timeserie.

    -   Two datasets were produced
        -   A timeserie (Mar-May) to run QPmat
        -   A maximum number of individuals each year to estimate recruitment
            -   Censuses from different years must be paired

## 2.2. Merge censuses

`{=html eval=FALSE, include=FALSE} Quadrants are not relevant for the analyses, so it is removed in the data handling process`

```{r message=FALSE, warning=FALSE}

#2025
census2025<-rbind(
  data.frame(Mar25,Month="3"),
  data.frame(Abr25,Month="4"),
  data.frame(Mai25,Month="5"))%>%
  as_tibble()%>%
  group_by(Site,Plot,Month)%>%    #Quadrants not included
  summarise(Imaturos=sum(Imaturos),
            Reprodutivos=sum(Reprodutivos))%>%
  ungroup()


#2024
census2024<-rbind(
  data.frame(Mar24,Month="3"),
  data.frame(Abr24,Month="4"),
  data.frame(Mai24,Month="5"))%>%
  as_tibble()%>%
  group_by(Site,Plot,Month)%>%    #Quadrants not included
  summarise(Imaturos=sum(Imaturos),
            Reprodutivos=sum(Reprodutivos))%>%
  ungroup()


### 2023
census2023<-rbind(
  data.frame(Mar23,Month="3"),
  data.frame(Abr23,Month="4"),
  data.frame(Mai23,Month="5"))%>%
  as_tibble()%>%
  group_by(Site,Plot,Month)%>%
  summarise(Imaturos=sum(Imaturos),
            Reprodutivos=sum(Reprodutivos))%>%
  ungroup()

### 2022
census2022<-rbind(
  data.frame(Mar22,Month="3"),
  data.frame(Abr22,Month="4"),
  data.frame(Mai22,Month="5"))%>%
  select(Site,Plot,Imaturos,Reprodutivos,Month)

census2022 # An example of a census merged along the year

#----------------------------------------------------
# Now merge the census across the years
#----------------------------------------------------

Census_all<-rbind(
  cbind(census2025,year="2025"),
  cbind(census2024,year="2024"),
  cbind(census2023,year="2023"),
  cbind(census2022,year="2022"))%>%
  pivot_longer(Imaturos:Reprodutivos,names_to="stage")%>%
  filter(!((Plot %in% c(8,9)) & year == 2025)) ##Remove censuses in plot 8 and 9 because it was not correctly sampled



#### Maximum number of individuals
Census_all_max<-rbind(
  cbind(census2025,year="2025"),
  cbind(census2024,year="2024"),
  cbind(census2023,year="2023"),
  cbind(census2022,year="2022"))%>%
  group_by(Site,year,Plot)%>%
  summarise(MaxIm=max(Imaturos),
            MaxRep=max(Reprodutivos))%>%
  mutate(MaxTot=ifelse(MaxIm>MaxRep,MaxIm,MaxRep))%>%
  pivot_longer(MaxIm:MaxTot,names_to="stage")


#Remove censuses in plot 8 and 9 because it was not correctly sampled
Census_all_max<-Census_all_max %>% filter(!((Plot %in% c(8,9)) & year == 2025)) 

#Remove census in plot 15 in 2025 as it was extinct a year before
Census_all_max<-Census_all_max %>% filter(!((Plot == 15) & year == 2025)) 

#Census_all_max  #View
```

### 2.2.1 Population size between plots and streams

```{r}
filter(Census_all_max,value>0)$value%>%range()

Census_all_max%>%
statrep(., group_vars = NULL,value_var = "value")
```

```{r}
# Mean  individuals by stream
Census_all_max%>%
statrep(., group_vars = c("Site"),value_var = "value")

# Mean  individuals by year
Census_all_max%>%
statrep(., group_vars = c("year"),value_var = "value")


# Mean  individuals by stage
Census_all_max%>%
statrep(., group_vars = c("stage"),value_var = "value")


# Mean  individuals by stream, year, stage
Census_all_max%>%
statrep(., group_vars = c("Site","year","stage"),value_var = "value")
```

#### Testing if there is differences between streams

Check theoretical distribution better describe abundance in plots and years: poisson or negatibe binomial.

```{r}
Census_all_max%>%
mutate(year=as.numeric(year))%>%
nest(data = -stage)%>%
 mutate(
    AICnb = map(data, ~ AIC(MASS::glm.nb(value ~ year*Site, data = .))),
    AICpois = map(data, ~ AIC(glm(value ~ year*Site, family=poisson(),data = .)))
    )%>%
  unnest(AICnb,AICpois)%>%select(-data)

```

Census_all_max

```{r}
Census_all_max%>%
#  filter(!c(year%in%c("2025")))%>%
mutate(year=as.numeric(year))%>%
nest(data = -stage)%>%
 mutate(
    fit = map(data, ~ MASS::glm.nb(value ~ year*Site, data = .)),
    tidy_fit = map(fit, ~ tidy(.) %>% mutate(across(c(estimate, p.value), ~ round(., 3))))
  ) %>%
  unnest(tidy_fit)%>%
group_by(stage)%>%
select(-c(fit,data))%>%
group_split()

```

## 2.3. Pairing censuses to estimate recruitment

```{r message=FALSE, warning=FALSE}
Timelags_base<-Census_all_max %>%
  mutate(year = as.numeric(year)) %>%        # make sure year is a numeric column
  group_by(Plot) %>%                         
  arrange(year, stage) %>%    # It is important to get all arranged as lead is dependent of the dataset order!                
  mutate(VAR = paste0(stage, ">", 
                      lead(stage, order_by = interaction(year,stage)))) %>%
# Store initial and next year to calculate recruitment
  mutate(t0y = year,
         t1y = lead(year, order_by = VAR))%>%   #lead function gets the next value, so, t+1 as they are sorted
  mutate(t0 = value, 
         t1 = lead(value, order_by = VAR)) %>% 
  # filters only years were t+1 (t1y) is older than initial year t (t0y),
  filter(t1y>t0y)%>%	#If this order is not what you want, change interaction to return same year variables
  arrange(Plot,VAR)

#### Max Rep in t0 vs. MaxTot in t1
#Pairing Maximum reprodutctive to Max Total

RepTot<-left_join(
  filter(Timelags_base,stage=="MaxRep")%>%select(Site:Plot,t0y,t0),  #Filter reproductive from t and total recruited individuals from t+1 (next line)
  filter(Timelags_base,stage=="MaxTot")%>%select(Site:Plot,t1y,t1))%>%
  mutate(VAR="MaxRep>MaxTot")%>%
  select(VAR,Site:t0y,t1y,t0,t1)%>%	#Reorder columns
  mutate(Site=as.factor(Site))%>%
  mutate(period=as.factor(paste0(t0y,"-",t1y)))
RepTot

# No longer used
##### Max Rep in t0 vs. MaxIm in t1
#RepIm<-left_join(
#  filter(Timelags_base,stage=="MaxRep")%>%select(Site:Plot,t0y,t0),
#  filter(Timelags_base,stage=="MaxIm")%>%select(Site:Plot,t1y,t1))%>%
#  mutate(VAR="MaxRep>MaxIm")%>%
#  select(VAR,Site:t0y,t1y,t0,t1)%>%	#Reorder columns
#  mutate(Site=as.factor(Site))%>%
#  mutate(period=as.factor(paste0(t0y,"-",t1y)))


```

## 2.4. Transform censuses in time series to estimate survival

```{r}

## 2025
Census2025_ts<-census2025%>%arrange(Site,Plot,Month)%>%
    filter(!(Plot %in% c(8,9,15)))%>% #Remove censuses from plot 8, 9 and 15
select(Plot,Month,Imaturos,Reprodutivos)%>%
pivot_longer(c(Imaturos,Reprodutivos),names_to="Stage",values_to="Indv")%>%
pivot_wider(names_from=Month,values_from="Indv")%>%
arrange(Plot)%>%
mutate(Plot_tag=paste0("Plot_",Plot))%>%
select(-c(Stage,Plot))%>%
 group_split(Plot_tag, .keep = TRUE) %>%
  `names<-`({.} %>% map(~ .x$Plot_tag[1]) %>% unlist()) %>%
  ## If you want to discard the grouping variable, do the following step as well
  map(~ .x %>% select(-Plot_tag))


## 2024
Census2024_ts<-census2024%>%arrange(Site,Plot,Month)%>%
select(Plot,Month,Imaturos,Reprodutivos)%>%
pivot_longer(c(Imaturos,Reprodutivos),names_to="Stage",values_to="Indv")%>%
pivot_wider(names_from=Month,values_from="Indv")%>%
arrange(Plot)%>%
mutate(Plot_tag=paste0("Plot_",Plot))%>%
select(-c(Stage,Plot))%>%
 group_split(Plot_tag, .keep = TRUE) %>%
  `names<-`({.} %>% map(~ .x$Plot_tag[1]) %>% unlist()) %>%
  ## If you want to discard the grouping variable, do the following step as well
  map(~ .x %>% select(-Plot_tag))

#Census2024_ts

## 2023
Census2023_ts<-census2023%>%arrange(Site,Plot,Month)%>%
select(Plot,Month,Imaturos,Reprodutivos)%>%
pivot_longer(c(Imaturos,Reprodutivos),names_to="Stage",values_to="Indv")%>%
pivot_wider(names_from=Month,values_from="Indv")%>%
arrange(Plot)%>%
mutate(Plot_tag=paste0("Plot_",Plot))%>%
select(-c(Stage,Plot))%>%
 group_split(Plot_tag, .keep = TRUE) %>%
  `names<-`({.} %>% map(~ .x$Plot_tag[1]) %>% unlist()) %>%
  ## If you want to discard the grouping variable, do the following step as well
  map(~ .x %>% select(-Plot_tag))

#Census2023_ts


## 2022
Census2022_ts<-census2022%>%arrange(Site,Plot,Month)%>%
select(Plot,Month,Imaturos,Reprodutivos)%>%
pivot_longer(c(Imaturos,Reprodutivos),names_to="Stage",values_to="Indv")%>%
pivot_wider(names_from=Month,values_from="Indv")%>%
arrange(Plot)%>%
mutate(Plot_tag=paste0("Plot_",Plot))%>%
select(-c(Stage,Plot))%>%
 group_split(Plot_tag, .keep = TRUE) %>%
  `names<-`({.} %>% map(~ .x$Plot_tag[1]) %>% unlist()) %>%
  ## If you want to discard the grouping variable, do the following step as well
  map(~ .x %>% select(-Plot_tag))



# Giving names to all plots to trace back

names(Census2022_ts)<-paste0(names(Census2022_ts),"_2022")
names(Census2023_ts)<-paste0(names(Census2023_ts),"_2023")
names(Census2024_ts)<-paste0(names(Census2024_ts),"_2024")
names(Census2025_ts)<-paste0(names(Census2025_ts),"_2025")


# Merge all timeseries
all_census_ts<-as.list(c(
		Census2022_ts,
		Census2023_ts,
		Census2024_ts,
		Census2025_ts))


# Check
## A timeserie from March to May
all_census_ts[1]


# Show censuses
all_census_df<-lapply(all_census_ts,cbind,Stages=c("Juveniles","Adults"))%>%
    Map(cbind, Plot_year = names(.),.)%>%do.call(rbind,.)%>%
    setNames(c("Plot_year","Mar", "Apr", "May","Stage"))%>%relocate(Stage, .before = "Mar")

all_census_df
```

Describe proportion of individuals in each stage along the year.

<!-- remember, these are proportions juveniles/adult, so they should have similar SD -->

```{r}
all_census_df %>%
  pivot_longer(cols = c(Mar, Apr, May), names_to = "Month", values_to = "Count") %>%
  group_by(Plot_year, Month) %>%
  filter(sum(Count) > 0) %>%  # Remove plots where adults and juveniles are 0 (Plot_15_2024)
  mutate(Proportion = Count / sum(Count)) %>%
  ungroup() %>%
  group_by(Month, Stage) %>%
  summarise(
    MeanProportion = mean(Proportion),
    SDProportion = sd(Proportion),
    .groups = "drop"
  ) %>%
  mutate(across(where(is.numeric), round, 3)) %>%#Note that SDProportion looks similar, but if 6 decimals are considered we spot differences! 
mutate(Month = factor(Month, levels = c("Mar", "Apr", "May")))%>%arrange(Month)
```

# 4. Inverse model implementation

## 4.1. Define the Parapiqueria life-cycle in a matrix format

Assuming the life cycle as:

```{R echo=FALSE}
library(DiagrammeR)

grViz("
digraph lifecycle {
  graph [rankdir=LR, splines=true]

  node [shape = circle, fontsize=12]
  
  J [label = 'Immat.']
  A [label = 'Adult']

  # Recrutamento (curvado para cima)
  A -> J [label = 'R', constraint=false, minlen=2, labeldistance=2, labelangle=95]

  # Sobrevivência juvenil
  J -> J [label = <S<sub>1,1</sub>>, color = 'grey']

  # Transição para adulto
  J -> A [label = <S<sub>1,2</sub>>, color = 'grey']
}
")

```

The resulting matrix is - 2x2 - Divided in juveniles and adults - Does not includes recruitment because it cannot be estimated within year (March-May)

$$
A=
\begin{bmatrix}
S_{1,1} & R_{1,2} \\
S_{2,1} & 0 \\
\end{bmatrix}
$$

where $A=U+F$

$$
U = 
\left(\begin{array}{ccc}  
S_{1,1} & 0 \\
S_{2,1} & 0 \\
\end{array}\right)
~~~~~\text{and}~~~~~~~
F = \left(\begin{array}{ccc}  
0 & R_{1,2} \\
0 & 0 \\
\end{array}\right)
$$

The respective MPM represents the individuals transition during the period Mar-May, represented by $U$

Non-zero elements in matrix $U$ are $S_{1,1}$ and $S_{2,1}$.

Once our matrix is defined, we creates an hypothetical matrix to help determine the necessary components to run the `QPmat` function

```{r, label="creates an hipothetical matrix"}
AA <- matrix(c(1,1,0,0),ncol=2)
AA
```

To run the `QPmat` function, we need to inform:

-   Demographic restrictions, represented by matrix $C$;
-   Non-zero elements already informed;
-   All vital rates have same weight $b$ element.

Matrix C is described as:

$$
C = 
\left(\begin{array}{ccc}  
  -1 & 0  \\          
  0 & -1   \\   
  1 & 1   \\   
\end{array}\right)
~~~~~~~~ \text{representing,} ~~~~~  
\begin{array}{c}
  \ S_{1,1} ≥ 0 \\
  \ S_{2,1} ≥ 0\\
  \ S_{1,1} + S_{2,1} ≤ 1 \\
\end{array}
$$

$S_{1,1} ≥ 0$ and $S_{1,1} ≥ 0$ means that components of the $U$ matrix cannot lower than 0. Also, the transition of juveniles to adults and stasis $S_{1,1} + S_{2,1} ≤ 1$ cannot be greater than 1.

To construct the C matrix in R, we do,

```{r}
C<- rbind(
  c(-1,  0),  # -a11 ≥ 0
  c( 0, -1),  # -a21 ≥ 0
  c( 1,  1)   # a11 + a21 ≤ 1
)
```

Define the non-zero elements

```{r}
nonzero<-which(AA> 0); nonzero
```

```{r}
b <- apply(C, 1, max)
```

# 5. Applying the quadratic programming

```{r}
U_list_bkp<-U_list<-NULL
for(i in 1:length(all_census_ts)){
U_list_bkp[[i]]<-U_list[[i]]<-tryCatch(
		QPmat(all_census_ts[[i]]%>%as.matrix(), 
			C,
			b,
			nonzero),
 error = function(e) { return(NA)})
}

names(U_list)<-names(U_list_bkp)<-names(all_census_ts)

U_list[50]
```

## 5.1. Remove plots where vital rates could not be estimated

-   Two plots at S11B could not have demographic information estimated because individuals are zero or too close to zero.

-   Plots are:

    -   Plot_19_2022 - Only adult individuals recorded

    -   Plot_15_2024 - Only 2 individuals in March

##### Decisions

-   Plot_15_2024 was below a extinction threshold, so, it is necessary to be included in the analyses.

    -   Plot_15_2025 - Removed because it was already extinct a year before

-   Plot_19_2022 we cannot decided if it is a sampling error or a biological process so it was removed

```{r}
# Detect plots with problems
problems_plots<-U_list_bkp[lapply(lapply(U_list_bkp,complete.cases),any,FALSE)=="FALSE"]

problems_plots

all_census_ts[names(problems_plots)]

# Create a list with a single MPM with all elements equal to zero
zero_mpm<-list()
zero_mpm[[1]]<-matrix(rep(0,4),2)

U_list_bkp[names(U_list_bkp) %in% names(problems_plots)]
U_list_bkp[names(U_list_bkp) %in% c("Plot_15_2024","Plot_15_2025")]<-zero_mpm  #Include zero matrices in the list of estiamted matrices
U_list_bkp[names(U_list_bkp) %in% names(problems_plots)]


#Census2022_ts$Plot_15_2022 #Show trajectory of the abundance
#Census2023_ts$Plot_15_2023
#Census2024_ts$Plot_15_2024
#Census2024_ts$Plot_15_2025

# Remove plot 15 2025 as it was already extincted

# remove Plot 19 2022 because we do not know if it was estimated correctly
U_list <- U_list_bkp[!(names(U_list)%in%c("Plot_19_2022","Plot_15_2025"))]
```

# 6. Quadratic programming efficiency

-   Simulate an hypothetical population to assess model's accuracy
-   Hypothetical population was created based on the matrix structure we expect for *Parapiqueria*.

```{r include=FALSE, echo=TRUE}
#file.edit("ModelToyv1.R") 
#source("ModelToyv1.R")
```

\#`{r fig.height=5, fig.width=14} #the object VRs_dif_df was created in "ModelToyv1.R" VRs_dif_df%>%   filter(matrix=="A2")%>%   ggplot(.,aes(x=census,y=Mean,group=census))+   geom_pointrange(aes(ymin=Mean-SD,ymax=Mean+SD,                       group=census,color=census,shape=matrix),                   position = position_dodge2(width = 0.7))+   ylab("Error")+xlab("# censuses")+   scale_y_continuous(label=scientific_10)+   scale_color_manual(values=c(     '#ff6347', '#6e8ab6', '#5b7bb3', '#496daf', '#375fa9', '#2350a4', '#00429d'))+   geom_hline(yintercept=0,color="red",linetype=2)+   scale_x_discrete(labels=function(l) parse(text=l))+   theme_minimal(base_size=24)+   facet_wrap(.~stages,scales="free",ncol=3) #`

# 7. Producing final matrix models

## 7.1 Transform observed recruitment in F matrices

```{r message=FALSE, warning=FALSE}
Recruit_asmx<- RepTot %>%
  mutate(id = paste0("Plot_", Plot, "_", year)) %>%  # Produce a list of plots_year similar to U_list
  mutate(
    fecundity = t1 / t0,  # fecundidade observada bruta
#    fecundity = ifelse(is.nan(fecundity) | fecundity < 0, 0, fecundity), # segurança
    F_matrix = map(fecundity, ~ {
      mat <- matrix(0, nrow=2, ncol=2)
      mat[1,2] <- .x
      mat
    })
  )


F_list <- Recruit_asmx %>%
  select(id, F_matrix) %>%
  mutate(id = as.character(id)) %>%
  { set_names(.$F_matrix, .$id) }


F_list[[1]]
```

## 7.2. Merging F matrices and U matrices

```{=html}
<!-- note that i cannot estimat recruitment from 2025 at the moment as 2026 year is lacking information.
So, only MPM from 2022-2024 were produced. So, F_list and U_list are better objects to estimate effect along the year in vital rates meanwhile mpm_list is the correct object to estimate lambda and make the simulations.
-->
```

```{r}
# Align the matrices to make sure F is defined for the correct plot

common_names <- intersect(names(U_list), names(F_list))

# 2. Subsetar e reordenar as listas
U_list_aligned <- U_list[common_names]
F_list_aligned <- F_list[common_names]

#Check if names are aligned
names(F_list_aligned) == names(U_list_aligned)

mpm_list <-Map(`+`, U_list_aligned, F_list_aligned)


```

### 7.3. Separe MPMs by streams

Split plots according to the streams.

-   Plots 1-10 are placed in the S11C;

-   Plots 11-20 are placed in the S11B;

```{r}
mpm_list_S11C<-mpm_list[grep("^Plot_([1-9]|10)_.*$", names(mpm_list))]
mpm_list_S11B<-mpm_list[grep("^Plot_(1[1-9]|20)_.*$", names(mpm_list))]

```

# 8. Summary results

Transform vital rates into a data.frame to proceed with statistical analyses

```{r}
#Accomodate matrices in two different datasets
F_mxdf<-data.frame(do.call(rbind,lapply(F_list,as.vector)),VR="vr")%>%rownames_to_column(var = "plot_year")

U_mxdf<-data.frame(do.call(rbind,lapply(U_list,as.vector)),VR="vr")%>%rownames_to_column(var = "plot_year")

# Merge these datasets
vr.df<-left_join(by="plot_year",
U_mxdf%>%  select(-X3),   #For dataset of U matrices, Recruitment (X3) is not relevant
F_mxdf%>%  select(c(plot_year,X3)) #For dataset of F matrices, Recruitment (X3) is the unique relevant informatiob
)%>% relocate(X3, .before = X4)%>%
setNames(c("plot_year","S1","S2","R","S4","VR"))%>%
separate("plot_year",sep="_",into = c("x", "Plot", "year"))%>%
select(-x)%>%
pivot_longer(S1:S4,values_to="value",names_to="vital_rate")%>%
mutate(Plot=as.numeric(Plot),
	 year=year)%>%
mutate(Site=ifelse(Plot<11,"S11C","S11B"))
```

## 8.1. Overall Vital rates

```{r}
vr.df%>%
filter(vital_rate!=c("S4"))%>%
statrep(., group_vars = c("vital_rate"),value_var = "value")
```

## 8.2. Vital rates by plot

```{r}
vr.df%>%
filter(vital_rate!=c("S4"))%>%
  statrep(., group_vars = c("vital_rate", "Site"),value_var = "value")%>%
    group_by(Site)%>% group_split()
```

```{r}
vr.df%>%
filter(vital_rate=="R")%>%
  statrep(., group_vars = c("year", "Site"),value_var = "value")%>%
    group_by(Site)
```

### 8.2.1. Checking if there is differences between plots

```{r}

#Stasis
vr.df%>%
filter(vital_rate=="S1")%>%
  aov(value~Site*year,data=.)%>%
  anova()

#Growth
vr.df%>%
filter(vital_rate=="S2")%>%
  aov(value~Site*year,data=.)%>%
  anova()

#Recruitment
vr.df%>%
filter(vital_rate=="R")%>%
  aov(value~Site*year,data=.)%>%
  anova()
```

### 7.2.2. Checking if vital rates are correlated to year

```{r}
vr.df%>%
  filter(vital_rate!="S4")%>%   
  filter(complete.cases(.))%>%       # Recruitment in  plot_15_2024 could not be extimeted as this plot reached exticntion in 2024. 
  select(-c(Plot,Site,VR))%>%
  mutate(year=as.numeric(year))%>%
  nest(data=c(year,value))%>% #only year and value are considered here
  mutate(pairwise= map(data, ~ cor.test(.$value, .$year,method="pearson")))%>% #cor.test instead of t.test
  pull()%>%
  purrr::set_names(c("Stasis[Immat]", "Growth[Immat.>Adult]", "Recruitment"))%>%
  tibble(
    Vital_rate = names(.),
    Correlation = map_dbl(., ~ .x$estimate[1]),
    conf_low = map_dbl(., ~ .x$conf.int[1]),
    conf_high = map_dbl(., ~ .x$conf.int[2]),
    t = map_dbl(., ~ .x$statistic),
    df = map_dbl(., ~ .x$parameter),
    p_value = map_dbl(., ~ .x$p.value))

```

```{r, fig.width=14,fig.height=5}
vr.df%>%
  statrep(., group_vars = c("vital_rate","year","Site"))%>%
  # filter(vital_rate!="R")%>%
  mutate(VR=ifelse(vital_rate=="R","Recruitment","Survival"))%>%
  mutate(stages=case_when(vital_rate=="S1"~ "Stasis[Immat]",
                          vital_rate=="S2"~ "Growth[Immat.>Adult]",
                          vital_rate=="R"~ "Recruitment",
                          vital_rate=="S4"~ "Surv[Adult]"))%>%
  mutate(stages=forcats::fct_relevel(stages, c("Stasis[Immat]","Growth[Immat.>Adult]", "Surv[Adult]","Recruitment")))%>%
  filter(!(vital_rate %in% c("S4")))%>%
  filter(!c(vital_rate=="R" & year==2025))%>%
  ungroup()%>%
  ggplot(.,aes(y=Mean,x=year,group=Site))+
  geom_pointrange(aes(ymin=Mean-SE,ymax=Mean+SE,color=Site,shape=year),alpha=0.8,
                  position = position_dodge2(width = 0.4))+
#  scale_x_discrete(labels=function(l) parse(text=l))+
  scale_x_discrete(drop=TRUE)+
  scale_color_manual(values=c("#ff9211","#6e86e7"))+
  theme_bw(base_size=24)+
  theme(legend.position="bottom")+
  facet_wrap(.~stages,scales="free")+
  xlab(NULL)+ylab(NULL)
```

```{r}
lamb_df<-lapply(mpm_list,lambda)%>%
  unlist()%>%data.frame(Lambda=.)%>%
  rownames_to_column(., var = "plot_year")%>%as_tibble()%>%
  separate("plot_year",sep="_",into = c("x", "Plot", "Year"))%>%
  select(-x)%>%
  mutate(Site=ifelse(Plot<11,"S11C","S11B"))

mean(lamb_df$Lambda)
sd(lamb_df$Lambda)
range(lamb_df$Lambda)

#TESTING DIFFERENCES
t.test(Lambda~Site,data=lamb_df)



lamb_df%>%statrep(., group_vars = c("Site"),value_var = "Lambda")

lamb_df%>%statrep(., group_vars = c("Year","Site"),value_var = "Lambda")


```

```{r,fig.height=5, fig.width=8}
lamb_df%>%
  statrep(., group_vars = c("Site","Year"),value_var = "Lambda")%>%
  #  mutate(VAR="PopGrowthRate")%>%
  ggplot(.,aes(y=Mean,x=Year,group=Site))+
  geom_hline(yintercept=1,col="red", linetype="longdash")+
  geom_pointrange(aes(ymin=Mean-SE,ymax=Mean+SE,color=Site,shape=Year),alpha=0.8,
                  position = position_dodge2(width = 0.7))+
  #  geom_line(aes(color = Site, group = Site), 
  #            position = position_dodge2(width = 0.7))+
  scale_x_discrete(labels=function(l) parse(text=l))+
  scale_color_manual(values=c("#ff9211","#6e86e7"))+
  theme_bw(base_size=16)+
  theme(legend.position="right")+
#  facet_grid(.~VAR)+
  xlab("Population growth rate")+ylab("Years")

```

# 8. Applying demographic tools: elasticity and LTRE

## 8.1. Elasticities of mean demographic parameters

```{r, result="asis"}

#Elasticities 
elas<-elasticity(mean(mpm_list))
elas

# Elasticities in Site S11B
elasticity(mean(mpm_list_S11B))

# Elasticities in Site S11C
elasticity(mean(mpm_list_S11C))
```

## 8.2. Life Table Response Experiment (LTRE)

```{r}
ltre_res<-LTRE(mean(mpm_list_S11B), mean(mpm_list_S11C))
ltre_sd<-sqrt(var2(LTRE(mpm_list_S11B, mean(mpm_list_S11C))))

```

```{r}
vr_perf<-data.frame(
 LTRE= as.vector(ltre_res),
 LTRE_sd= as.vector(ltre_sd),
 Elasticities= as.vector(elas),
  vr=c("S11","S21","R","S22"))



vr_perf%>%
  mutate(Elasticities=Elasticities*100)
```

```{r, fig.height=5, fig.width=12}
vr_perf%>%pivot_longer(!c(vr, LTRE_sd),names_to="variable",values_to="values")%>%
  filter(vr!="S22")%>%
  ggplot(.,aes(x=vr,y=values))+
  geom_col()+
  facet_wrap(.~variable,scales="free")+
  theme_minimal()
  
```

## 8.2. Life table response by year

```{r}

LTREyear_df<- data.frame(
    rbind(
    #2022
        LTRE(
          mean(mpm_list_S11B[grep("2022$", names(mpm_list_S11B), value = TRUE)]),
          mean(mpm_list_S11C[grep("2022$", names(mpm_list_S11C), value = TRUE)]))%>%
          as.vector(),
    #2023
        LTRE(
          mean(mpm_list_S11B[grep("2023$", names(mpm_list_S11B), value = TRUE)]),
          mean(mpm_list_S11C[grep("2023$", names(mpm_list_S11C), value = TRUE)]))%>%
        as.vector(),
    #2024
        LTRE(
          mean(mpm_list_S11B[grep("2024$", names(mpm_list_S11B), value = TRUE)]),
          mean(mpm_list_S11C[grep("2024$", names(mpm_list_S11C), value = TRUE)]))%>%
        as.vector())
  )



LTREyear_df %>%
  rowwise() %>%
  mutate(
    total = sum(abs(c_across(everything()))),
    across(everything(), ~ abs(.x) / total)*100
  ) %>%
  select(-c(total,X4))%>%
  cbind(Year=c("2022","2023","2024"),.)%>%
    setNames(c("Year","S1","S2","R"))
```

# 9. Extinction risk

Three steps must be performed first:

1.  Define the initial number of individuals based on the mean value of immature individuals and adult

2 Simulate vital rates to include in the model

3.  Create a set of matrices with these new estimated variables

## 9.1. Define the initial number of individuals

```{r}
Mean_indiv<-Census_all_max%>%
  #filter(  Remove 1% dos dados para evitar outliers
  #  value < quantile(value,.995) & 
  #  value > quantile(value,.005))%>%
  group_by(stage)%>%
  summarise(Mean=mean(value),
            Median=median(value),
            sd=sd(value))

Mean_indiv
```

## 9.4. Extinction growth rate

```{r}
#'-------------------------------------------------------------------------
# Create proptable_modif a special prop table ------------------
#'-------------------------------------------------------------------------
## Rationale  --------------
# proptable_modif is an adaptation of default prop.table
# This function allow to include FALSE or TRUE when there is no legitime true or false extinction 
#'-------------------------------------------------------------------------
proptable_modif <- function(data, threshold) {
  # equivalent to prop.table(table(apply(data,1,sum)> n_threshold))*100
  res <- table(factor(apply(data, 1, sum) > threshold, levels = c(FALSE, TRUE)))
  # Equivalent to prop.table(ext10.probS11B)*100
  prop <- prop.table(res) * 100
  return(prop)
}
##'-------------------------------------------------------------------------

```

```{r}


n_init<-Mean_indiv$Median[1:2] # define initial population
n_threshold<-sum(n_init)*.10 # Define extinction threshold: 10% of the initial population size

proj.pop<-stoch.quasi.ext(mpm_list, 
              n0 = n_init, 
              Nx=n_threshold,
              maxruns=10,
              tmax = 10, nreps=1000)
matplot(proj.pop, xlab="Years", ylab="Cumulative extinction risk (%)", 
        type='l', lty=1, col="grey20", las=1,
        main="Extinction risk \n (Proportion of simulations crossing extinction threshold of 10% initial population")

```

```{r}

#Project population for 10 years based on estimated parameters
projS11B_10<-stoch.projection(mpm_list_S11B, 
                              n_init,	
                              tmax=10,nreps=10000)
projS11C_10<-stoch.projection(mpm_list_S11C, 
                              n_init,tmax=10,nreps=10000)


# Project with all matrices together 
projALL_10<-stoch.projection(mpm_list,
                             n_init,tmax=10,nreps=10000)

projALL_30<-stoch.projection(mpm_list,
                             n_init,tmax=30,nreps=10000)
```

```{r}

data.frame(rbind(
  proptable_modif(projALL_10, n_threshold),
  proptable_modif(projALL_30, n_threshold)),
  row.names = c("10 years", "30 years"))%>%setNames(c("Extincted","Persistent"))%>%
  print()

```

```{r}
# Chi-square of extinction rate between streams
data.frame(rbind(
  proptable_modif(projS11B_10, n_threshold),
  proptable_modif(projS11C_10, n_threshold)),
  row.names = c("S11B", "S11C"))%>%setNames(c("Extincted","Persistent"))%>%
  print()%>%chisq.test()
```


## 9.5 Simulating different scenarios

Create a function to automatise the vital rates reduction. This function is a adaptation of `stoch.quasi.ext` from `popbio` package.

This adaptation includes the parameter "damage" with a vector informing scenarios of vital rates reduction. Note all vital rates are impacted together.

```{r}
Myviab_func<-function (matrices, n0, Nx, tmax = 50, maxruns = 10, nreps = 5000, 
                       prob = NULL, sumweight = NULL, verbose = TRUE,damage=damage) {
  damage=damage
  if (is.list(matrices)) {
    matrices <- matrix(unlist(matrices), ncol = length(matrices))
  }
  x <- length(n0)
  if (is.null(sumweight)) {
    sumweight <- rep(1, x)
  }
  y <- dim(matrices)[2]
  ext <- matrix(numeric(maxruns * tmax), ncol = maxruns)
  for (h in 1:maxruns) {
    if (verbose) {
      message("Calculating extinction probability for run ", 
              h)
    }
    prob.ext <- numeric(tmax)
    for (i in 1:nreps) {
      n <- n0
      for (t in 1:tmax) {
        col <- sample(1:y, 1, prob = prob)
        A <- matrix(matrices[, col], nrow = x)
        n <- ((A-(A*damage)) %*% n)
        N <- sum(sumweight * round(n))
        if (N < Nx) {
          prob.ext[t] <- prob.ext[t] + 1
          break
        }
      }
    }
    prob.ext <- cumsum(prob.ext/nreps) #Extinctions by number of replications
    ext[, h] <- prob.ext
  }
  ext
}
```

-   Define de impacts. a sequence of impact from 0% to 50% reduction in vital rates

```{r}
sim_damage<-seq(0,0.5,by=0.05)
sim_damage


# My color system
Mycolors<-c(
  '#5e90a5', '#7e7a89', '#9e636e', '#bf4d52', '#df3637', '#ff201b', '#cc1a16', '#991310', '#660d0b', '#330605', '#000000'
#  '#A7C7E7', '#6699CC', '#FFC857', '#FF8C42', '#FF3C38', '#D7263D', '#A01227', '#6F0E19', '#3B080F', '#000000'
)
```

Perform the simulation

```{r echo=TRUE, message=FALSE, warning=FALSE, include=FALSE}
tempS11C<-tempS11B<-temp<-NULL
outS11C<-outS11B<-out<-NULL

tmax=11   #Years simulated (from t0 to t10)

# Simulation with all plots together
for(i in 1:length(sim_damage)){
  temp<-Myviab_func(mpm_list, 
                    n0 = n_init, 
                    Nx=n_threshold,        
                    maxruns=100,                  
                    tmax = tmax, nreps=100,
                    damage=sim_damage[i])
  out[[i]]<-data.frame(Extinct.rate=apply(temp,1,mean),
                       SD=apply(temp,1,sd),
                       Damage=sim_damage[i],
                       t=seq(1,tmax,by=1))
  print(paste0("Simulating damage at ",sim_damage[i]*100,"%" ))
}


# Simulation considering only S11B
for(i in 1:length(sim_damage)){
  tempS11B<-Myviab_func(mpm_list_S11B, 
                    n0 = n_init, 
                    Nx=n_threshold,        
                    maxruns=100,                   #
                    tmax = tmax, nreps=100,
                    damage=sim_damage[i],
                    verbose = FALSE)
  outS11B[[i]]<-data.frame(Extinct.rate=apply(tempS11B,1,mean),
                       SD=apply(tempS11B,1,sd),
                       Damage=sim_damage[i],
                       t=seq(1,tmax,by=1),
                    verbose = FALSE)
  print(paste0("Simulating damage at ",sim_damage[i]*100,"%" ))
}


# Simulation considering only S11C
for(i in 1:length(sim_damage)){
  tempS11C<-Myviab_func(mpm_list_S11C, 
                    n0 = n_init, 
                    Nx=n_threshold,        #Mean_indiv[3,3]/10 representa 10% dos indivíduos médios
                    maxruns=100,                   # Número de réplicas em cada simulação?
                    tmax = tmax, nreps=100,        # Número de simulações
                    damage=sim_damage[i],
                    verbose = FALSE)
  outS11C[[i]]<-data.frame(Extinct.rate=apply(tempS11C,1,mean),
                       SD=apply(tempS11C,1,sd),
                       Damage=sim_damage[i],
                       t=seq(1,tmax,by=1),
                    verbose = FALSE)
  print(paste0("Simulating damage at ",sim_damage[i]*100,"%" ))
}



```

Calculate the number of simulations crossing the extinction threshold to extimate the persistence probability.

```{r}
viab_para<-do.call(rbind,out)%>%
  mutate(Persistprop=100-(Extinct.rate*100),
         ymin=100-((Extinct.rate-SD)*100),
         ymax=100-((Extinct.rate+SD)*100))
  
viab_para[viab_para>100]<-100
viab_para[viab_para<0]<-0


viab_para%>%filter(t==10)
```

```{r, fig.height=5, fig.width=12}
viab_para%>%
  #  mutate(dano=as.factor(dano))%>%
  ggplot(.,aes(x=t-1,y=Persistprop,group=Damage))+
  geom_line(aes(color=Damage*100))+
  geom_pointrange(aes(ymin=ymin, ymax=ymax,color=Damage*100))+
  #  viridis::scale_color_viridis(option="magma")+
  scale_color_stepsn(
    #    colours = c("red", "yellow", "green", "yellow", "red"),
    # colours = viridis::viridis(n = 7, option = "inferno",direction=-1) ,
    colours = Mycolors)+   theme_classic(base_size=24)+
  scale_x_continuous(breaks=seq(0,10,by=1),expand = c(0, 0))+
  scale_y_continuous(labels = scales::percent_format(scale = 1),
                     expand = c(0, 0),
                     breaks=c(seq(0,100,by=25)))+
#  geom_hline(yintercept=10,color="tomato",linetype="dashed")+
  labs(color="Impact/Reduction (%)",
       y="Persistence probability",
       x="Years projected")+
  theme(legend.position="right")
```


```{r}
viab_para%>%filter(t==10)%>%
  mutate(Extinct.rate=Extinct.rate*100,
         SD=SD*100)
```

```{r}
viab_S11B<-do.call(rbind,outS11B)%>%
  mutate(Persistprop=100-(Extinct.rate*100),
         ymin=100-((Extinct.rate-SD)*100),
         ymax=100-((Extinct.rate+SD)*100))
  

viab_S11B[viab_S11B>100]<-100
viab_S11B[viab_S11B<0]<-0

viab_S11C<-do.call(rbind,outS11C)%>%
  mutate(Persistprop=100-(Extinct.rate*100),
         ymin=100-((Extinct.rate-SD)*100),
         ymax=100-((Extinct.rate+SD)*100))
  
viab_S11C[viab_S11C>100]<-100
viab_S11C[viab_S11C<0]<-0



viab_S11B%>%filter(t==10)%>%filter(t==10)%>%
  mutate(Extinct.rate=Extinct.rate*100,
         SD=SD*100)


viab_S11C%>%filter(t==10)%>%filter(t==10)%>%
  mutate(Extinct.rate=Extinct.rate*100,
         SD=SD*100)


```


```{r, fig.height=8, fig.width=18}
cowplot::plot_grid(labels = "AUTO",label_size=24,
  do.call(rbind,outS11B)%>%
  #  mutate(dano=as.factor(dano))%>%
  ggplot(.,aes(x=t-1,y=Extinct.rate*100,group=Damage))+
  geom_line(aes(color=Damage*100))+
  geom_pointrange(aes(ymin=(Extinct.rate-SD)*100, ymax=(Extinct.rate+SD)*100,color=Damage*100))+
  #  viridis::scale_color_viridis(option="magma")+
  scale_color_stepsn(
    #    colours = c("red", "yellow", "green", "yellow", "red"),
    # colours = viridis::viridis(n = 7, option = "inferno",direction=-1) ,
    colours = Mycolors)+   theme_classic(base_size=19)+
  scale_x_continuous(breaks=seq(0,10,by=1),expand = c(0, 0))+
  scale_y_continuous(labels = scales::percent_format(scale = 1),
                     expand = c(0, 0),
                     breaks=c(seq(0,100,by=25)))+
  labs(color="Impact/Reduction (%)",
       y="Extinction probability",
       x="Years projected",
       title="S11B")+
  theme(legend.position="bottom"),
  
  
  do.call(rbind,outS11C)%>%
  #  mutate(dano=as.factor(dano))%>%
  ggplot(.,aes(x=t-1,y=Extinct.rate*100,group=Damage))+
  geom_line(aes(color=Damage*100))+
  geom_pointrange(aes(ymin=(Extinct.rate-SD)*100, ymax=(Extinct.rate+SD)*100,color=Damage*100))+
  #  viridis::scale_color_viridis(option="magma")+
  scale_color_stepsn(
    #    colours = c("red", "yellow", "green", "yellow", "red"),
    # colours = viridis::viridis(n = 7, option = "inferno",direction=-1) ,
    colours = Mycolors)+   theme_classic(base_size=19)+
  scale_x_continuous(breaks=seq(0,10,by=1),expand = c(0, 0))+
  scale_y_continuous(labels = scales::percent_format(scale = 1),
                     expand = c(0, 0),
                     breaks=c(seq(0,100,by=25)))+
  labs(color="Impact/Reduction (%)",
       y="Extinction probability per plot",
       x="Years projected",
       title="S11C")+
  theme(legend.position="bottom")
)
  
  
```




# Glossary

C

:   C: is a matrix somehow